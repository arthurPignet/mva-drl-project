{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports\n",
    "\n",
    "The above imports are not at all mandatory in order to have the following code work. This cell is here to ensure that your setup is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Agent on pendulum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acme\n",
    "\n",
    "from src.environments.inverted_pendulum import InvertedPendulumEnv, inverted_pendulum_env_factory\n",
    "from src.agents import DDPGAgent\n",
    "from src.interaction_loops import ddpg_parallel_interaction_loop, evaluation_parallel_interaction_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum_environment = InvertedPendulumEnv(for_evaluation=True)  #### WARNING, I changed the env\n",
    "pendulum_environment_spec = acme.make_environment_spec(pendulum_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "# define the agent\n",
    "num_evaluation_steps = 1000\n",
    "max_learner_steps=50\n",
    "pendulum_agent = DDPGAgent(seed=0, \n",
    "learning_rate=5e-4,\n",
    "gamma=.95, \n",
    "environment_spec=pendulum_environment_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "state argument does not appear valid. It should be a mapping but is of type <class 'src.data.Transition'>. For reference the parameters for apply are `apply(params, rng, ...)`` for `hk.transform` and `apply(params, state, rng, ...)` for `hk.transform_with_state`.\nThe argument was: Transition(obs_tm1=Traced<ShapedArray(float32[15,3])>with<DynamicJaxprTrace(level=0/1)>, action_tm1=Traced<ShapedArray(float32[15,1])>with<DynamicJaxprTrace(level=0/1)>, reward_t=Traced<ShapedArray(float32[15])>with<DynamicJaxprTrace(level=0/1)>, discount_t=Traced<ShapedArray(float32[15])>with<DynamicJaxprTrace(level=0/1)>, obs_t=Traced<ShapedArray(float32[15,3])>with<DynamicJaxprTrace(level=0/1)>, done=Traced<ShapedArray(int32[15])>with<DynamicJaxprTrace(level=0/1)>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arthur/drl/mva-drl-project/notebooks/DDPG.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Barthur_syft/home/arthur/drl/mva-drl-project/notebooks/DDPG.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m ddpg_parallel_interaction_loop(pendulum_agent, env_factory\u001b[39m=\u001b[39;49minverted_pendulum_env_factory, max_learner_steps\u001b[39m=\u001b[39;49mmax_learner_steps, num_actors\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, buffer_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/drl/mva-drl-project/src/interaction_loops.py:124\u001b[0m, in \u001b[0;36mddpg_parallel_interaction_loop\u001b[0;34m(agent, env_factory, max_learner_steps, buffer_size, batch_size, num_actors)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/interaction_loops.py?line=121'>122</a>\u001b[0m   replay\u001b[39m.\u001b[39madd(timestep\u001b[39m.\u001b[39mobservation[i],actions[i],ts\u001b[39m.\u001b[39mreward[i],ts\u001b[39m.\u001b[39mdiscount[i],ts\u001b[39m.\u001b[39mobservation[i],ts\u001b[39m.\u001b[39mstep_type[i])\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/interaction_loops.py?line=122'>123</a>\u001b[0m transitions \u001b[39m=\u001b[39m replay\u001b[39m.\u001b[39msample_batch(\u001b[39mmin\u001b[39m(batch_size,\u001b[39mlen\u001b[39m(replay\u001b[39m.\u001b[39m_memory)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> <a href='file:///home/arthur/drl/mva-drl-project/src/interaction_loops.py?line=123'>124</a>\u001b[0m logs \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mlearner_step(transitions)\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/interaction_loops.py?line=124'>125</a>\u001b[0m \u001b[39mif\u001b[39;00m learner_step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/interaction_loops.py?line=125'>126</a>\u001b[0m   \u001b[39mprint\u001b[39m(pretty_print(logs))\n",
      "File \u001b[0;32m~/drl/mva-drl-project/src/agents.py:229\u001b[0m, in \u001b[0;36mDDPGAgent.learner_step\u001b[0;34m(self, transition)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearner_step\u001b[39m(\u001b[39mself\u001b[39m, transition: Transition) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, chex\u001b[39m.\u001b[39mArrayNumpy]:\n\u001b[0;32m--> <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=228'>229</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learner_state, logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner_state, transition)\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=229'>230</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m logs\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/drl/mva-drl-project/src/agents.py:223\u001b[0m, in \u001b[0;36mDDPGAgent._update_fn\u001b[0;34m(self, learner_state, transition)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=221'>222</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fn\u001b[39m(\u001b[39mself\u001b[39m, learner_state: LearnerState, transition: Transition) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[LearnerState, LogsDict]:\n\u001b[0;32m--> <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=222'>223</a>\u001b[0m     (loss, (aux, state)), grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grad(learner_state\u001b[39m.\u001b[39;49mparams, transition)\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=223'>224</a>\u001b[0m     udpates, new_opt_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39mupdate(grads, learner_state\u001b[39m.\u001b[39mopt_state, learner_state\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=224'>225</a>\u001b[0m     new_params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(learner_state\u001b[39m.\u001b[39mparams, udpates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/drl/mva-drl-project/src/agents.py:198\u001b[0m, in \u001b[0;36mDDPGAgent.__init__.<locals>.apply_loss_2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=196'>197</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_loss_2\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=197'>198</a>\u001b[0m     (loss, aux), state \u001b[39m=\u001b[39m apply_loss(\u001b[39m*\u001b[39;49margs,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/arthur/drl/mva-drl-project/src/agents.py?line=198'>199</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss, (aux, state)\n",
      "File \u001b[0;32m~/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py:210\u001b[0m, in \u001b[0;36mwithout_apply_rng.<locals>.apply_fn\u001b[0;34m(params, state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=207'>208</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(params, state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=208'>209</a>\u001b[0m   check_rng_kwarg(kwargs)\n\u001b[0;32m--> <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=209'>210</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mapply(params, state, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py:395\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=392'>393</a>\u001b[0m \u001b[39m\"\"\"Applies your function injecting parameters and state.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=393'>394</a>\u001b[0m params \u001b[39m=\u001b[39m check_mapping(\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m, params)\n\u001b[0;32m--> <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=394'>395</a>\u001b[0m state \u001b[39m=\u001b[39m check_mapping(\u001b[39m\"\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m\"\u001b[39;49m, state)\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=395'>396</a>\u001b[0m rng \u001b[39m=\u001b[39m to_prng_sequence(\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=396'>397</a>\u001b[0m     rng, err_msg\u001b[39m=\u001b[39m(APPLY_RNG_STATE_ERROR \u001b[39mif\u001b[39;00m state \u001b[39melse\u001b[39;00m APPLY_RNG_ERROR))\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=397'>398</a>\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(params\u001b[39m=\u001b[39mparams, state\u001b[39m=\u001b[39mstate, rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n",
      "File \u001b[0;32m~/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py:431\u001b[0m, in \u001b[0;36mcheck_mapping\u001b[0;34m(name, mapping)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=428'>429</a>\u001b[0m   mapping \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=429'>430</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mapping, Mapping):\n\u001b[0;32m--> <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=430'>431</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m argument does not appear valid. It should be a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=431'>432</a>\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmapping but is of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(mapping)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=432'>433</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mFor reference the parameters for apply are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=433'>434</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`apply(params, rng, ...)`` for `hk.transform` and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=434'>435</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`apply(params, state, rng, ...)` for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=435'>436</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`hk.transform_with_state`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=436'>437</a>\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe argument was: \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/arthur/anaconda3/envs/drl/lib/python3.9/site-packages/haiku/_src/transform.py?line=437'>438</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mapping\n",
      "\u001b[0;31mTypeError\u001b[0m: state argument does not appear valid. It should be a mapping but is of type <class 'src.data.Transition'>. For reference the parameters for apply are `apply(params, rng, ...)`` for `hk.transform` and `apply(params, state, rng, ...)` for `hk.transform_with_state`.\nThe argument was: Transition(obs_tm1=Traced<ShapedArray(float32[15,3])>with<DynamicJaxprTrace(level=0/1)>, action_tm1=Traced<ShapedArray(float32[15,1])>with<DynamicJaxprTrace(level=0/1)>, reward_t=Traced<ShapedArray(float32[15])>with<DynamicJaxprTrace(level=0/1)>, discount_t=Traced<ShapedArray(float32[15])>with<DynamicJaxprTrace(level=0/1)>, obs_t=Traced<ShapedArray(float32[15,3])>with<DynamicJaxprTrace(level=0/1)>, done=Traced<ShapedArray(int32[15])>with<DynamicJaxprTrace(level=0/1)>)."
     ]
    }
   ],
   "source": [
    "ddpg_parallel_interaction_loop(pendulum_agent, env_factory=inverted_pendulum_env_factory, max_learner_steps=max_learner_steps, num_actors=16, batch_size=32, buffer_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.expand_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "  ddpg_parallel_interaction_loop(pendulum_agent, env_factory=inverted_pendulum_env_factory, max_learner_steps=max_learner_steps, sequence_length=sequence_length, num_actors=16)\n",
    "  plot_policy_on_pendulum(pendulum_agent, 50)\n",
    "  evaluation_parallel_interaction_loop(pendulum_agent, env_factory=inverted_pendulum_env_factory, sequence_length=200, num_actors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks import ValueNetworkDDPG, PolicyNetworkDDPG, PolicyNetwork\n",
    "from src.data import Transition\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Transition\n",
    "observation = pendulum_environment_spec.observations.generate_value()\n",
    "action = pendulum_environment_spec.actions.generate_value()\n",
    "\n",
    "tr = Transition(\n",
    "    obs_tm1= observation[None],\n",
    "    action_tm1= action[None],\n",
    "    reward_t= jnp.zeros(1)[None],\n",
    "    discount_t=jnp.zeros(1)[None],\n",
    "    obs_t=observation[None],\n",
    "    done=jnp.zeros(1)[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.concatenate([tr.obs_t, tr.action_tm1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(transition):\n",
    "    action = PolicyNetworkDDPG(environment_spec.actions)(transition.obs_tm1, True)\n",
    "    return action\n",
    "\n",
    "def f1(obs):\n",
    "    return hk.BatchApply(PolicyNetworkDDPG(environment_spec.actions))(obs, True)\n",
    "    \n",
    "init_loss, apply_loss = hk.without_apply_rng(hk.transform_with_state(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_loss(rng,tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.obs_tm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "474ad13565867984240761aae35b74af33d0ec1a4a5a71bd466163dfcadb0220"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('drl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
